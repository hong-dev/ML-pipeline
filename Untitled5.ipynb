{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "from collections import namedtuple\n",
    "from itertools import product\n",
    "\n",
    "from ml_class import TestSplit, Preprocessor#, RobustScaler, StandardScaler\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--input INPUT] [--prediction PREDICTION]\n",
      "                             [--report REPORT] [--target TARGET]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/soo/.local/share/jupyter/runtime/kernel-23852365-e2c5-4f6a-a3e8-52bee98fc824.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    scalers = [RobustScaler, StandardScaler]\n",
    "    models = [LogisticRegression, DecisionTreeClassifier]\n",
    "    dataset_type = ['train', 'validation', 'test']\n",
    "\n",
    "    # scalers_models_combination = list(product(scalers, models))\n",
    "    index_combination = list(product(scalers, models, dataset_type))\n",
    "\n",
    "    a = namedtuple('Index', 'scaler model data')\n",
    "    index_combination_a = [a(index[0].__name__, index[1].__name__, index[2]) for index in index_combination]\n",
    "    \n",
    "    # print(scalers_models_combination)\n",
    "    \n",
    "    # comb_n = []\n",
    "    # for index in scalers_models_combination:\n",
    "        # scaler = index[0]\n",
    "        # model = index[1]\n",
    "\n",
    "        # combination_name = f\"{scaler.__name__}-{model.__name__}\"\n",
    "        # comb_n.append(combination_name)\n",
    "    \n",
    "    # a = list(product(comb_n, dataset_type))\n",
    "\n",
    "    index = pd.MultiIndex.from_tuples(index_combination_a, names=[\"scaler\", \"model\", \"data\"])\n",
    "\n",
    "    report_df = pd.DataFrame(index=index, columns=[\"Precision\", \"Recall\", \"Accuracy\", \"F1\"])\n",
    "\n",
    "    prediction_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "    for index in index_combination_a:\n",
    "        # scaler = index[0]\n",
    "        # model = index[1]\n",
    "        # combination_name = f\"{scaler.__name__}-{model.__name__}\"\n",
    "\n",
    "        preprocessor = Preprocessor(eval(index.scaler))\n",
    "        model = eval(index.model)()#(max_iter=700)\n",
    "\n",
    "        train_score, validation_score = process_train_data(preprocessor, model)\n",
    "        test_prediction, test_score = process_test_data(preprocessor, model)\n",
    "        prediction_df[f\"{index.scaler}-{index.model}\"] = test_prediction\n",
    "\n",
    "        dataset_type = {'train': train_score, 'validation': validation_score, 'test': test_score}\n",
    "        add_report(report_df, index.scaler, index.model, dataset_type)\n",
    "\n",
    "    prediction_df.to_csv('./result/{}'.format(get_arguments().prediction))\n",
    "    report_df.to_csv('./result/{}'.format(get_arguments().report))\n",
    "\n",
    "def process_train_data(preprocessor, model):\n",
    "    # get dataset\n",
    "    train_data = get_data('marketing_train.csv')\n",
    "\n",
    "    # split data\n",
    "    target = get_arguments().target\n",
    "    X_train, X_validation, y_train, y_validation = TestSplit().split_test(train_data, target)\n",
    "\n",
    "    # fit & transform\n",
    "    X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "    X_validation_transformed = transform_data(preprocessor, X_validation)\n",
    "\n",
    "    # fit & predict\n",
    "    model.fit(X_train_transformed, y_train)\n",
    "    X_train_prediction = predict_data(model, X_train_transformed)\n",
    "    X_validatrion_prediction = predict_data(model, X_validation_transformed)\n",
    "\n",
    "    # score\n",
    "    train_score = get_scores(y_train, X_train_prediction)\n",
    "    validation_score = get_scores(y_validation, X_validatrion_prediction)\n",
    "\n",
    "    return train_score, validation_score\n",
    "\n",
    "def process_test_data(preprocessor, model):\n",
    "    \"\"\"\n",
    "    return: prediction, score\n",
    "    \"\"\"\n",
    "\n",
    "    # get dataset\n",
    "    arguments = get_arguments()\n",
    "    test_data = get_data(arguments.input)\n",
    "    target = arguments.target\n",
    "\n",
    "    # transform\n",
    "    test_transformed = transform_data(preprocessor, test_data.drop(target, axis=1))\n",
    "\n",
    "    # predict\n",
    "    test_prediction = predict_data(model, test_transformed)\n",
    "        \n",
    "    # score\n",
    "    test_score = get_scores(test_data[target], test_prediction)\n",
    "\n",
    "    return test_prediction, test_score\n",
    "\n",
    "def get_arguments():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--input', default='marketing_test.csv', help='Write file name you want to predict')\n",
    "    parser.add_argument('--prediction', default='pred.csv', help='Write file name you want to save prediction')\n",
    "    parser.add_argument('--report', default='report.csv', help='Write file name you want to save report')\n",
    "    parser.add_argument('--target', default='insurance_subscribe', help='Write target feature')\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "def get_data(file_name):\n",
    "    return pd.read_csv('./data/{}'.format(file_name))\n",
    "\n",
    "def transform_data(preprocessor, dataset_without_target):\n",
    "    return preprocessor.transform(dataset_without_target)\n",
    "\n",
    "def predict_data(model, transformed_data):\n",
    "    return model.predict(transformed_data)\n",
    "\n",
    "def get_scores(actual_y, predicted_y):\n",
    "    funcs = [precision_score, recall_score, accuracy_score, f1_score]\n",
    "    scores = []\n",
    "\n",
    "    for func in funcs:\n",
    "        scores.append(func(actual_y, predicted_y))\n",
    "\n",
    "    print(scores)\n",
    "    return scores\n",
    "\n",
    "def add_report(report, scaler, model, dataset_type):\n",
    "    for data, score in dataset_type.items():\n",
    "        report.loc[(scaler, model, data)] = score\n",
    "    \n",
    "    return report\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "# python ml_data.py --input “marketing_test.csv” --prediction “pred.csv” --report “report.csv”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler #as SklearnRobustScaler\n",
    "from sklearn.preprocessing import StandardScaler as SklearnStandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder as SklearnOneHotEncoder\n",
    "from sklearn.impute import SimpleImputer as SklearnSimpleImputer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "\n",
    "# class StandardScaler(SklearnStandardScaler):\n",
    "#     def transform(self, X):\n",
    "#         return pd.DataFrame(super().transform(X), columns=X.columns, index=X.index)\n",
    "\n",
    "# class RobustScaler(SklearnRobustScaler):\n",
    "#     def transform(self, X):\n",
    "#         return pd.DataFrame(super().transform(X), columns=X.columns, index=X.index)\n",
    "\n",
    "# class SimpleImputer(SklearnSimpleImputer):\n",
    "#     def transform(self, X):\n",
    "#         return pd.DataFrame(super().transform(X), columns=X.columns, index=X.index)\n",
    "\n",
    "# class OneHotEncoder(SklearnOneHotEncoder):\n",
    "#     def transform(self, X):\n",
    "#         sparse_matrix = super(OneHotEncoder, self).transform(X)\n",
    "#         new_columns = self.get_column_names(X=X)\n",
    "#         return pd.DataFrame(sparse_matrix.toarray(), columns=new_columns, index=X.index)\n",
    "\n",
    "#     def get_column_names(self, X):\n",
    "#         new_columns = []\n",
    "#         for i, column in enumerate(X.columns):\n",
    "#             j = 0\n",
    "#             while j < len(self.categories_[i]):\n",
    "#                 new_columns.append(f'{column}_{self.categories_[i][j]}')\n",
    "#                 j += 1\n",
    "#         return new_columns\n",
    "        \n",
    "class TestSplit:\n",
    "    def split_test(self, dataset, target):\n",
    "        self.features_without_target = dataset.drop(target, axis=1)\n",
    "        self.target_feature = dataset[target]\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(self.features_without_target, self.target_feature) #기본비율\n",
    "        return X_train, X_test, y_train, y_test\n",
    "        \n",
    "class Preprocessor(TransformerMixin):\n",
    "    def __init__(self, scaler):\n",
    "        self.scaler = scaler\n",
    "\n",
    "    def transform_numeric_features(self):\n",
    "        return Pipeline(steps=[\n",
    "            ('imputer', SklearnSimpleImputer(strategy='median')),\n",
    "            ('scaler', self.scaler())\n",
    "            ])\n",
    "\n",
    "    @staticmethod\n",
    "    def transform_categorical_features():\n",
    "        return Pipeline(steps=[\n",
    "            ('imputer', SklearnSimpleImputer(strategy='most_frequent')),\n",
    "            ('onehot', SklearnOneHotEncoder())\n",
    "            ])\n",
    "\n",
    "    def transform_columns(self):\n",
    "        return ColumnTransformer(transformers = [\n",
    "            ('nums', self.transform_numeric_features(), self.numeric_features.columns),\n",
    "            ('cats', self.transform_categorical_features(), self.categorical_features.columns)\n",
    "            ])\n",
    "\n",
    "    def get_column_names(self):\n",
    "        # nums_names = self.column_transformer.named_transformers_['nums']['scaler'].get_feature_names(self.categorical_features.columns) #.fit_transform(self.numeric_features).columns\n",
    "        cats_names = self.column_transformer.named_transformers_['cats']['onehot'].get_feature_names(self.categorical_features.columns) #.fit_transform(self.categorical_features).columns\n",
    "        feat_names = np.concatenate([self.numeric_features.columns, cats_names])\n",
    "        return feat_names\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.dataset = X\n",
    "        self.numeric_features = X.select_dtypes(np.number)\n",
    "        self.categorical_features = X.select_dtypes(exclude=np.number)\n",
    "        self.column_transformer = self.transform_columns()\n",
    "        self.column_transformer.fit(X)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        transformed_data = self.column_transformer.transform(X)\n",
    "        column_names = self.get_column_names()\n",
    "        return pd.DataFrame(transformed_data, columns=column_names, index=X.index)\n",
    "\n",
    "\n",
    "# train_data = pd.read_csv('./data/marketing_train.csv')\n",
    "# test_data = pd.read_csv('./data/marketing_test.csv')\n",
    "\n",
    "# target = \"insurance_subscribe\"\n",
    "# X_train, X_val, y_train, y_val = TestSplit().split_test(train_data, target)\n",
    "\n",
    "# preprocessor = Preprocessor()\n",
    "# X_train_transformed = preprocessor.fit_transform(X_train)\n",
    "# X_test_transformed = preprocessor.transform(X_val)\n",
    "# test_transformed = preprocessor.transform(test_data.drop(target, axis=1))\n",
    "\n",
    "\n",
    "# model = LogisticRegression(max_iter=600)\n",
    "# model.fit(X_train_transformed, y_train)\n",
    "\n",
    "# X_train_prediction = model.predict(X_train_transformed)\n",
    "# X_validation_prediction = model.predict(X_test_transformed)\n",
    "# test_prediction = model.predict(test_transformed)\n",
    "\n",
    "# X_train_prediction = predict(X_train_transformed)\n",
    "# X_validation_prediction = predict(X_test_transformed)\n",
    "# test_prediction = predict(test_transformed)\n",
    "\n",
    "# def predict(transformed_data):\n",
    "#     return model.predict(transformed_data)\n",
    "\n",
    "# def make_pred():\n",
    "#     prediction_df = pd.DataFrame(test_prediction, columns=[\"Predicted value\"]).rename_axis(\"ID\")\n",
    "#     prediction_df.to_csv(\"pred.csv\")\n",
    "\n",
    "\n",
    "def get_scores(actual_y, predicted_y):\n",
    "    funcs = [precision_score, recall_score, accuracy_score, f1_score]\n",
    "    # columns = []\n",
    "    scores = []\n",
    "\n",
    "    for func in funcs:\n",
    "        # columns.append(func.__name__)\n",
    "        scores.append(func(actual_y, predicted_y))\n",
    "\n",
    "    # report_df = pd.DataFrame(columns=columns)\n",
    "    # report_df.loc['Robust-Logistic'] = scores\n",
    "\n",
    "    return scores\n",
    "\n",
    "\n",
    "def make_report():\n",
    "    report_df = pd.DataFrame(index=[\"Logistic\"], columns=[\"Precision\", \"Recall\", \"Accuracy\", \"F1\"])\n",
    "\n",
    "    compare_y = [(y_train, X_train_prediction), (y_val, X_validation_prediction), (test_data[target], test_prediction)]\n",
    "    for y_data in compare_y:\n",
    "        actual_y, predicted_y = y_data[0], y_data[1]\n",
    "        # report_df.loc[('Logistic', 'train')] = get_scores(actual_y, predicted_y)\n",
    "        \n",
    "    print(report_df)\n",
    "    return report_df\n",
    "\n",
    "# make_report()\n",
    "\n",
    "# print(get_scores(y_train, X_train_prediction))\n",
    "# print(get_scores(y_test, X_test_prediction))\n",
    "# print(get_scores(test_data[target], test_prediction))\n",
    "\n",
    "# get_scores.to_csv(\"report.csv\")\n",
    "\n",
    "\n",
    "# def main():\n",
    "#     parser = argparse.ArgumentParser()\n",
    "#     parser.add_argument('--input', required=True)\n",
    "#     parser.add_argument('--prediction', default='pred.csv', help='Write file name you want to save prediction')\n",
    "#     parser.add_argument('--report', default='report.csv', help='Write file name you want to save report')\n",
    "\n",
    "#     train, test = read_data()\n",
    "#     transformed_data = preprocess()\n",
    "#     model  = model_train()\n",
    "\n",
    "# def read_data(path='marketing_train.csv'):\n",
    "#     return pd.read_csv(path)\n",
    "\n",
    "# def test():\n",
    "#     read_data(input_path)\n",
    "\n",
    "# 1. train 하기\n",
    "# 2. input으로 들어온 데이터 읽기\n",
    "# 3. 데이터 transform, prediction, score  하기\n",
    "# 4. 저장하기 \n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "\n",
    "# k-fold, model seletor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = pathlib.Path('~/solid{}').with_suffix('.abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('~/solid{}.abc')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib_dir_path = './joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'joblib/preprocessor.joblib'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(pathlib.Path(joblib_dir_path, '{}').with_suffix('.joblib')).format('preprocessor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('abc/def')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathlib.Path('abc', 'def')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/solid_preprocessor.abc'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(path).format('_preprocessor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/solid.abc'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path.join('~/solid'+'.abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = os.path.join(joblib_dir_path, '{}' + '.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./joblib/a.joblib'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.format('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = os.path.join(joblib_dir_path, '{}').endswith('.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-2337d7da5ae8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pandas' from '/home/soo/.pyenv/versions/3.8.3/envs/aaa-3.8.3/lib/python3.8/site-packages/pandas/__init__.py'>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2,3], [4,5,6], [7,8,9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-081881d390cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/aaa-3.8.3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/aaa-3.8.3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 )\n\u001b[0;32m--> 357\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "pd.concat(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-b305ecbd9365>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/aaa-3.8.3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIndexes\u001b[0m \u001b[0mhave\u001b[0m \u001b[0moverlapping\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m     op = _Concatenator(\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mobjs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/aaa-3.8.3/lib/python3.8/site-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    355\u001b[0m                     \u001b[0;34m\"only Series and DataFrame objs are valid\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m                 )\n\u001b[0;32m--> 357\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0;31m# consolidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot concatenate object of type '<class 'list'>'; only Series and DataFrame objs are valid"
     ]
    }
   ],
   "source": [
    "pd.concat(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('requirements.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas\n",
      "scikit-learn\n",
      "numpy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas\n",
      "scikit-learn\n",
      "numpy\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('requirements.txt', 'r') as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-571e9fb02258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file."
     ]
    }
   ],
   "source": [
    "f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.DataFrame(a, columns=['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  1  2  3\n",
       "1  4  5  6\n",
       "2  7  8  9"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 2, 3], [4, 5, 6], [7, 8, 9]]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[1, 2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[4, 5, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[7, 8, 9]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "0  [1, 2, 3]\n",
       "1  [4, 5, 6]\n",
       "2  [7, 8, 9]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([b, d])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.Series(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 2, 3]\n",
       "1    [4, 5, 6]\n",
       "2    [7, 8, 9]\n",
       "dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [1,2,3]\n",
    "list_2 = [4,5,6]\n",
    "list_3 = [7,8,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2\n",
       "0  1  2  3\n",
       "1  4  5  6\n",
       "2  7  8  9"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([list_1, list_2, list_3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Field elements must be 2- or 3-tuples, got '7'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-0c52ae636977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/aaa-3.8.3/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMultiIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/aaa-3.8.3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_validate_dtype\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0;31m# a compound dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.8.3/envs/aaa-3.8.3/lib/python3.8/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mpandas_dtype\u001b[0;34m(dtype)\u001b[0m\n\u001b[1;32m   1872\u001b[0m     \u001b[0;31m# raise a consistent TypeError if failed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1873\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1874\u001b[0;31m         \u001b[0mnpdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1875\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mSyntaxError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1876\u001b[0m         \u001b[0;31m# np.dtype uses `eval` which can raise SyntaxError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Field elements must be 2- or 3-tuples, got '7'"
     ]
    }
   ],
   "source": [
    "e = pd.Series(a[0], a[1], a[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [1, 2, 3]\n",
       "1    [4, 5, 6]\n",
       "2    [7, 8, 9]\n",
       "dtype: object"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list.extend([3, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, [3, 4], 3, 4, 3, 4]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from utils import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Preprocessor(StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<utils.Preprocessor at 0x7fc5435f24f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(transformers=[('numeric',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer(strategy='median')),\n",
       "                                                 ('standardscaler',\n",
       "                                                  StandardScaler())]),\n",
       "                                 None),\n",
       "                                ('categorical',\n",
       "                                 Pipeline(steps=[('simpleimputer',\n",
       "                                                  SimpleImputer(strategy='most_frequent')),\n",
       "                                                 ('onehotencoder',\n",
       "                                                  OneHotEncoder())]),\n",
       "                                 None)])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p._build_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Preprocessor' object has no attribute 'column_transformer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-870b5b129fb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_column_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/solid/ot_task_1/utils.py\u001b[0m in \u001b[0;36mget_column_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;31m# get column names for dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_column_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         cats_names = self.column_transformer.named_transformers_[\n\u001b[0m\u001b[1;32m     42\u001b[0m             \u001b[0;34m\"categorical\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         ][1].get_feature_names(self.categorical_features)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Preprocessor' object has no attribute 'column_transformer'"
     ]
    }
   ],
   "source": [
    "p.get_column_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "tmp = tempfile.NamedTemporaryFile(suffix=\".csv\")\n",
    "# tmp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tempfile._TemporaryFileWrapper at 0x7f9f248a2490>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(tmp.name, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(tmp.name, 'w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.write('abc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(tmp.name, 'r'):\n",
    "    f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(tmp.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tmp/tmp5s7njbve.csv'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.mkditmp.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
